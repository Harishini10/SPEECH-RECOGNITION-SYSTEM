# SPEECH-RECOGNITION-SYSTEM

A FUNCTIONAL SYSTEM CAPABLE OF TRANSCRIBING SHORT AUDIO CLIP

*COMPANY*: CODTECH IT SOLUTIONS

*NAME*: DEVATHA HARISHINI

*INTERN ID*: CT12NXC

*DOMAIN*: ARTIFICAL INTELLIGENCE

*DURATION*: 8 WEEKS

*MENTOR*: NEELA SANTHOSH

# The objective of this task is to develop a functional Speech-to-Text (STT) system using pre-trained models and widely used speech recognition libraries. The system is designed to transcribe short audio clips into text efficiently, leveraging deep learning and natural language processing techniques. This technology is widely applied in real-world scenarios such as voice assistants (Google Assistant, Siri, Alexa), automated transcription services (Otter.ai, Rev), customer service automation, medical dictation systems, and accessibility tools for hearing-impaired users. The tools and technologies used in this project include Google Colab, which provides a cloud-based environment for running Python scripts without requiring local setup, and Python as the primary programming language for scripting and implementing the STT system. The SpeechRecognition library is used for basic speech recognition tasks and supports multiple engines, including the Google Web Speech API, which is free but requires an internet connection. For an offline and more accurate transcription system, we utilize Wav2Vec 2.0 by Facebook AI, a state-of-the-art pre-trained deep learning model that converts speech to text efficiently, even in noisy environments. Additionally, Librosa, a powerful library for processing audio files, helps extract essential features and resample waveforms. The PyTorch framework is used to load and run Wav2Vec 2.0, enabling efficient machine learning-based speech transcription. To generate synthetic speech for testing purposes, we use Pyttsx3, a Python-based text-to-speech (TTS) engine that converts text into spoken words. For storing and managing audio files in a cloud-based setting, Google Drive integration in Colab can be used. References for this project include official documentation from SpeechRecognition, Facebook Wav2Vec 2.0, and Librosa. Additional references include YouTube tutorials such as "Speech-to-Text using Python and Deep Learning" (YouTube Link) and "Implementing Wav2Vec 2.0 for Speech Recognition" (YouTube Link). Other useful sources include academic research papers on automatic speech recognition (ASR) and open datasets like Mozilla Common Voice and LibriSpeech, which provide high-quality speech samples for training and testing STT systems. Real-time applications of speech-to-text technology extend to call centers, where customer interactions are automatically transcribed and analyzed, education, where students and researchers use automatic transcription tools for lecture notes, journalism, where reporters use STT to convert interviews into text, and law enforcement, where speech-to-text systems help in transcribing police reports and legal documents. In healthcare, speech recognition assists doctors in dictating patient notes, reducing paperwork and enhancing efficiency. The technology is also widely used in language translation services, where spoken words are transcribed and translated in real time. With advancements in deep learning and artificial intelligence, speech-to-text models are becoming more accurate, reducing errors and improving accessibility for diverse languages and dialects. This project demonstrates a practical implementation of such a system using state-of-the-art tools and pre-trained models, making speech recognition technology accessible and easy to integrate into real-world applications.

# OUTPUT



